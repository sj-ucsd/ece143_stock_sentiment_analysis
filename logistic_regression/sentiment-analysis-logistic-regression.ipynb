{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yahooquery\n",
    "import pandas as pd\n",
    "from sklearn import dummy, metrics, model_selection, preprocessing\n",
    "from sklearn import model_selection\n",
    "#from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "#from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from pandas_datareader import data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yahoo_news(symbol):\n",
    "    #start_date = date(2020, 6, 1)\n",
    "    #end_date = date(2021, 1, 29)\n",
    "    data = []\n",
    "    run_Dict = []\n",
    "    ticker = yahooquery.Ticker(symbol)\n",
    "      \n",
    "    news = ticker.news(2000,start=\"2021-01-29\")\n",
    "    news = pd.DataFrame(news)\n",
    "    \n",
    "    news=news[[\"provider_publish_time\",\"title\", \"summary\"]]\n",
    "    #news['date'] = pd.fr(news['provider_publish_time']).dt.strftime('%m-%d-%Y')\n",
    "    news = news.sort_values(by=['provider_publish_time'])\n",
    "    news['date'] = pd.to_datetime(news['provider_publish_time'],unit='s').dt.strftime(\"%Y-%m-%d\")\n",
    "    news.set_index(pd.to_datetime(news['date']), inplace=True)\n",
    "    news.drop('date', axis=1)\n",
    "    nltk.download(\"vader_lexicon\")\n",
    "    sentimentAnalyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "    news[\"compound\"] = [sentimentAnalyser.polarity_scores(v)['compound'] if isinstance(v,str) else v for v in news[\"summary\"]]\n",
    "    news[\"negative\"] = [sentimentAnalyser.polarity_scores(v)['neg'] if isinstance(v,str) else v for v in news[\"summary\"]]\n",
    "    news[\"positive\"] = [sentimentAnalyser.polarity_scores(v)['pos'] if isinstance(v,str) else v for v in news[\"summary\"]]\n",
    "    news[\"neutral\"] = [sentimentAnalyser.polarity_scores(v)['neu'] if isinstance(v,str) else v for v in news[\"summary\"]]\n",
    "\n",
    "\n",
    "    #news['date'] = pd.to_datetime(news['date']).\n",
    "    print(news.columns)\n",
    "    return news\n",
    "\n",
    "def get_sentiment_from_news(news):\n",
    "    news_sentiment = news[['date', 'compound']]\n",
    "    news_sentiment.set_index(pd.to_datetime(news_sentiment['date']), inplace=True)\n",
    "    news_sentiment = news_sentiment['compound']\n",
    "    total_sentiment = news_sentiment.groupby('date').agg(lambda x: sum(x))\n",
    "    total_sentiment = total_sentiment.rename('Total Sentiment')\n",
    "    nArticles = news_sentiment.groupby('date').count()\n",
    "    avg_sentiment = total_sentiment/nArticles\n",
    "    avg_sentiment = avg_sentiment.rename('Avg Sentiment')\n",
    "    sentiment_data = pd.concat([total_sentiment, avg_sentiment], axis=1)\n",
    "    sentiment_data = sentiment_data.reindex(df.index, method='ffill')\n",
    "    return sentiment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yahoo_dataframe(symbol):\n",
    "  # Get historical data\n",
    "  #symbol = 'AAPL'\n",
    "    ticker = yahooquery.Ticker(symbol)\n",
    "    df = pd.DataFrame(ticker.history(start='2020-01-29', end='2021-01-29'))\n",
    "    df=data.DataReader(symbol, 'yahoo', '20200129', '20210129').reset_index()\n",
    "    #df = df[['Date','Adj Close', 'Volume']]\n",
    "    #(df[:10].style.format(dict(Date='{:%d/%m/%Y}'))\n",
    "    #  .background_gradient(subset='Volume',cmap='Blues')\n",
    "    #  .background_gradient(subset='Adj Close',cmap='Blues')\n",
    "    #)\n",
    "    #df.Volume.plot()\n",
    "    #Volume = df['Volume']/10000000\n",
    "    #Volume.plot.bar()\n",
    "    #df[\"Adj Close\"].plot()\n",
    "    #dates = pd.DataFrame(pd.date_range('20200203',periods=8*31))\n",
    "    df.set_index(pd.to_datetime(df['Date']), inplace=True)\n",
    "    df = df.drop(['Date'], axis=1)\n",
    "    return df\n",
    "def process_stock_data(filename, df):\n",
    "    stock_file = pd.read_csv(filename)\n",
    "    stock_file.set_index(pd.to_datetime(stock_file['Date']), inplace=True)\n",
    "    stock_file.drop('Date', axis=1)\n",
    "    stock_file = stock_file.reindex(df.index, method='bfill')\n",
    "    stock_file = stock_file.drop('Date', axis=1)\n",
    "    stock_file = stock_file.drop('Period Ending', axis=1)\n",
    "    return stock_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_Y_for_ML(df):\n",
    "    output = df['Adj Close']\n",
    "    output.rename('Stock Price')\n",
    "    advance = df['Adj Close'].shift(-10)\n",
    "    advance = advance.rename('Short Term Advance')\n",
    "    advance2 = df['Adj Close'].shift(-50)\n",
    "    advance2 = advance2.rename('Mid Term Advance')\n",
    "    gt = pd.concat([output, advance, advance2], axis=1)\n",
    "    df['Short Term Change'] = ((gt['Short Term Advance'] - gt['Adj Close'])/gt['Adj Close'])*100\n",
    "    df['Mid Term Change'] = ((gt['Mid Term Advance'] - gt['Adj Close'])/gt['Adj Close'])*100\n",
    "    #short term 3% mid term 5% long term 10%\n",
    "    df['stm'] = df['Short Term Change']\n",
    "    df.loc[df['stm'] > 3, 'stm' ] = 3\n",
    "    df.loc[df['stm'] < -3, 'stm' ] = -3\n",
    "    df.loc[(df['stm']>-3)& (df['stm']<3),'stm'] = 0\n",
    "    df.loc[df['stm'] == 3, 'stm' ] = 'up'\n",
    "    df.loc[df['stm'] == -3, 'stm' ] = 'down'\n",
    "    df.loc[df['stm']==0,'stm'] = 'neutral'\n",
    "    #df[df['stm']<-3]=-3\n",
    "    #df[(df['stm']>-3) & (df['stm']<3)]=0\n",
    "      #print(gt[9:110])\n",
    "      #gt['Short Term Change'].plot()\n",
    "\n",
    "    #Y = gt[['Short Term Change']]\n",
    "    #return Y\n",
    "def prepare_data_X_for_ML(df):\n",
    "    df['Weekly Sentiment'] = df['Avg Sentiment'].rolling(5, win_type='triang').sum()\n",
    "    df['Monthly Sentiment'] = df['Avg Sentiment'].rolling(20, win_type='triang').sum()\n",
    "    avg_monthly_sentiment = df['Monthly Sentiment'].sum()/len(df['Monthly Sentiment'])\n",
    "    avg_week = df['Weekly Sentiment'].sum()/len(df['Monthly Sentiment'])\n",
    "    #X = df[10:]\n",
    "    df['Monthly Sentiment'] =  df['Monthly Sentiment'].fillna(avg_monthly_sentiment)\n",
    "    df['Weekly Sentiment'] = df['Weekly Sentiment'].fillna(avg_week)\n",
    "    #X=X.drop(['Date','Estimated_Revenue','Reported_Revenue','Estimated_EPS','Reported_EPS','Period Ending'],axis=1)\n",
    "    #return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/sagarjogadhenu/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['provider_publish_time', 'title', 'summary', 'date', 'compound',\n",
      "       'negative', 'positive', 'neutral'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#main code\n",
    "symbol='AAPL'\n",
    "df = get_yahoo_dataframe(symbol)\n",
    "df\n",
    "stock_file=process_stock_data('/Users/sagarjogadhenu/Downloads/TinyEarn/AAPL.csv', df)\n",
    "#print(stock_file)\n",
    "df = df.join(stock_file)\n",
    "news = get_yahoo_news(symbol)\n",
    "sentiment_data=get_sentiment_from_news(news)\n",
    "#print(sentiment_data)\n",
    "df = df.join(sentiment_data)\n",
    "df[['Total Sentiment', 'Avg Sentiment']] = df[['Total Sentiment', 'Avg Sentiment']].fillna(method='ffill')\n",
    "prepare_data_Y_for_ML(df)\n",
    "prepare_data_X_for_ML(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#short term analysis\n",
    "df = df.drop(columns='Mid Term Change')\n",
    "df = df[df['stm'].notna()] # drop NA from stm\n",
    "df['stm'] = df['stm'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Estimated_EPS</th>\n",
       "      <th>Reported_EPS</th>\n",
       "      <th>Surprise_EPS</th>\n",
       "      <th>Estimated_Revenue</th>\n",
       "      <th>Reported_Revenue</th>\n",
       "      <th>Total Sentiment</th>\n",
       "      <th>Avg Sentiment</th>\n",
       "      <th>Short Term Change</th>\n",
       "      <th>stm</th>\n",
       "      <th>Weekly Sentiment</th>\n",
       "      <th>Monthly Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>81.962502</td>\n",
       "      <td>80.345001</td>\n",
       "      <td>81.112503</td>\n",
       "      <td>81.084999</td>\n",
       "      <td>216229200.0</td>\n",
       "      <td>80.270790</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.11</td>\n",
       "      <td>88017.80</td>\n",
       "      <td>91819.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.121216</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.587579</td>\n",
       "      <td>1.870699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>81.022499</td>\n",
       "      <td>79.687500</td>\n",
       "      <td>80.135002</td>\n",
       "      <td>80.967499</td>\n",
       "      <td>126743200.0</td>\n",
       "      <td>80.154472</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.11</td>\n",
       "      <td>88017.80</td>\n",
       "      <td>91819.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.546820</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.587579</td>\n",
       "      <td>1.870699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>80.669998</td>\n",
       "      <td>77.072502</td>\n",
       "      <td>80.232498</td>\n",
       "      <td>77.377502</td>\n",
       "      <td>199588400.0</td>\n",
       "      <td>76.600517</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.11</td>\n",
       "      <td>88017.80</td>\n",
       "      <td>91819.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.237703</td>\n",
       "      <td>up</td>\n",
       "      <td>0.587579</td>\n",
       "      <td>1.870699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>78.372498</td>\n",
       "      <td>75.555000</td>\n",
       "      <td>76.074997</td>\n",
       "      <td>77.165001</td>\n",
       "      <td>173985600.0</td>\n",
       "      <td>76.390160</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.11</td>\n",
       "      <td>88017.80</td>\n",
       "      <td>91819.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.595236</td>\n",
       "      <td>up</td>\n",
       "      <td>0.587579</td>\n",
       "      <td>1.870699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>79.910004</td>\n",
       "      <td>78.407501</td>\n",
       "      <td>78.827499</td>\n",
       "      <td>79.712502</td>\n",
       "      <td>136616400.0</td>\n",
       "      <td>78.912079</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.11</td>\n",
       "      <td>88017.80</td>\n",
       "      <td>91819.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.736877</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.587579</td>\n",
       "      <td>1.870699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>132.630005</td>\n",
       "      <td>130.229996</td>\n",
       "      <td>132.429993</td>\n",
       "      <td>132.050003</td>\n",
       "      <td>105158200.0</td>\n",
       "      <td>131.852966</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.04</td>\n",
       "      <td>63388.91</td>\n",
       "      <td>64698.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.231738</td>\n",
       "      <td>up</td>\n",
       "      <td>1.940400</td>\n",
       "      <td>2.078669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>130.169998</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>129.190002</td>\n",
       "      <td>128.979996</td>\n",
       "      <td>100620900.0</td>\n",
       "      <td>128.787552</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.04</td>\n",
       "      <td>63388.91</td>\n",
       "      <td>64698.0</td>\n",
       "      <td>0.7469</td>\n",
       "      <td>0.025755</td>\n",
       "      <td>10.993954</td>\n",
       "      <td>up</td>\n",
       "      <td>1.671785</td>\n",
       "      <td>2.176127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>129.690002</td>\n",
       "      <td>126.860001</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>128.800003</td>\n",
       "      <td>91951100.0</td>\n",
       "      <td>128.607819</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.04</td>\n",
       "      <td>63388.91</td>\n",
       "      <td>64698.0</td>\n",
       "      <td>7.8081</td>\n",
       "      <td>0.260270</td>\n",
       "      <td>10.295034</td>\n",
       "      <td>up</td>\n",
       "      <td>0.935527</td>\n",
       "      <td>2.294586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>131.449997</td>\n",
       "      <td>128.490005</td>\n",
       "      <td>128.759995</td>\n",
       "      <td>130.889999</td>\n",
       "      <td>88636800.0</td>\n",
       "      <td>130.694702</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.04</td>\n",
       "      <td>63388.91</td>\n",
       "      <td>64698.0</td>\n",
       "      <td>10.9573</td>\n",
       "      <td>0.304369</td>\n",
       "      <td>4.736803</td>\n",
       "      <td>up</td>\n",
       "      <td>0.577925</td>\n",
       "      <td>2.454672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>128.759995</td>\n",
       "      <td>130.800003</td>\n",
       "      <td>128.910004</td>\n",
       "      <td>90221800.0</td>\n",
       "      <td>128.717667</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.04</td>\n",
       "      <td>63388.91</td>\n",
       "      <td>64698.0</td>\n",
       "      <td>4.6131</td>\n",
       "      <td>0.209686</td>\n",
       "      <td>2.365985</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.550249</td>\n",
       "      <td>2.610667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  High         Low        Open       Close       Volume  \\\n",
       "Date                                                                      \n",
       "2020-01-29   81.962502   80.345001   81.112503   81.084999  216229200.0   \n",
       "2020-01-30   81.022499   79.687500   80.135002   80.967499  126743200.0   \n",
       "2020-01-31   80.669998   77.072502   80.232498   77.377502  199588400.0   \n",
       "2020-02-03   78.372498   75.555000   76.074997   77.165001  173985600.0   \n",
       "2020-02-04   79.910004   78.407501   78.827499   79.712502  136616400.0   \n",
       "...                ...         ...         ...         ...          ...   \n",
       "2021-01-08  132.630005  130.229996  132.429993  132.050003  105158200.0   \n",
       "2021-01-11  130.169998  128.500000  129.190002  128.979996  100620900.0   \n",
       "2021-01-12  129.690002  126.860001  128.500000  128.800003   91951100.0   \n",
       "2021-01-13  131.449997  128.490005  128.759995  130.889999   88636800.0   \n",
       "2021-01-14  131.000000  128.759995  130.800003  128.910004   90221800.0   \n",
       "\n",
       "             Adj Close  Estimated_EPS  Reported_EPS  Surprise_EPS  \\\n",
       "Date                                                                \n",
       "2020-01-29   80.270790           1.14          1.25          0.11   \n",
       "2020-01-30   80.154472           1.14          1.25          0.11   \n",
       "2020-01-31   76.600517           1.14          1.25          0.11   \n",
       "2020-02-03   76.390160           1.14          1.25          0.11   \n",
       "2020-02-04   78.912079           1.14          1.25          0.11   \n",
       "...                ...            ...           ...           ...   \n",
       "2021-01-08  131.852966           0.69          0.73          0.04   \n",
       "2021-01-11  128.787552           0.69          0.73          0.04   \n",
       "2021-01-12  128.607819           0.69          0.73          0.04   \n",
       "2021-01-13  130.694702           0.69          0.73          0.04   \n",
       "2021-01-14  128.717667           0.69          0.73          0.04   \n",
       "\n",
       "            Estimated_Revenue  Reported_Revenue  Total Sentiment  \\\n",
       "Date                                                               \n",
       "2020-01-29           88017.80           91819.0              NaN   \n",
       "2020-01-30           88017.80           91819.0              NaN   \n",
       "2020-01-31           88017.80           91819.0              NaN   \n",
       "2020-02-03           88017.80           91819.0              NaN   \n",
       "2020-02-04           88017.80           91819.0              NaN   \n",
       "...                       ...               ...              ...   \n",
       "2021-01-08           63388.91           64698.0           0.0000   \n",
       "2021-01-11           63388.91           64698.0           0.7469   \n",
       "2021-01-12           63388.91           64698.0           7.8081   \n",
       "2021-01-13           63388.91           64698.0          10.9573   \n",
       "2021-01-14           63388.91           64698.0           4.6131   \n",
       "\n",
       "            Avg Sentiment  Short Term Change      stm  Weekly Sentiment  \\\n",
       "Date                                                                      \n",
       "2020-01-29            NaN           1.121216  neutral          0.587579   \n",
       "2020-01-30            NaN           0.546820  neutral          0.587579   \n",
       "2020-01-31            NaN           5.237703       up          0.587579   \n",
       "2020-02-03            NaN           3.595236       up          0.587579   \n",
       "2020-02-04            NaN           1.736877  neutral          0.587579   \n",
       "...                   ...                ...      ...               ...   \n",
       "2021-01-08       0.000000           8.231738       up          1.940400   \n",
       "2021-01-11       0.025755          10.993954       up          1.671785   \n",
       "2021-01-12       0.260270          10.295034       up          0.935527   \n",
       "2021-01-13       0.304369           4.736803       up          0.577925   \n",
       "2021-01-14       0.209686           2.365985  neutral          0.550249   \n",
       "\n",
       "            Monthly Sentiment  \n",
       "Date                           \n",
       "2020-01-29           1.870699  \n",
       "2020-01-30           1.870699  \n",
       "2020-01-31           1.870699  \n",
       "2020-02-03           1.870699  \n",
       "2020-02-04           1.870699  \n",
       "...                       ...  \n",
       "2021-01-08           2.078669  \n",
       "2021-01-11           2.176127  \n",
       "2021-01-12           2.294586  \n",
       "2021-01-13           2.454672  \n",
       "2021-01-14           2.610667  \n",
       "\n",
       "[244 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['High', 'Low', 'Open', 'Close', 'Volume', 'Adj Close', 'Estimated_EPS',\n",
       "       'Reported_EPS', 'Surprise_EPS', 'Estimated_Revenue', 'Reported_Revenue',\n",
       "       'Total Sentiment', 'Avg Sentiment', 'Short Term Change', 'stm',\n",
       "       'Weekly Sentiment', 'Monthly Sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick columns of interest and split data for training and testing\n",
    "x_cols = ['Volume','Estimated_EPS','Reported_EPS', 'Surprise_EPS', 'Estimated_Revenue', 'Reported_Revenue', 'Weekly Sentiment']\n",
    "#x_cols = ['Volume', 'Weekly Sentiment']\n",
    "\n",
    "y_cols = ['stm']\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(df[x_cols],df[y_cols]\\\n",
    "                                                                                  , test_size=0.3)\n",
    "cols = X_train.columns\n",
    "std = preprocessing.StandardScaler()\n",
    "X_train.loc[:, cols] = std.fit_transform(X_train)\n",
    "X_test.loc[:,cols] = std.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='sag', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lr= LogisticRegression(multi_class='multinomial',solver='sag')\n",
    "lr.fit(X_train,np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5540540540540541"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test,np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4189189189189189"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(X_train,np.ravel(y_train))\n",
    "dt.score(X_test,np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5135135135135135"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn.fit(X_train,np.ravel(y_train))\n",
    "kn.score(X_test,np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sagarjogadhenu/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5135135135135135"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,np.ravel(y_train))\n",
    "rf.score(X_test,np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5675675675675675"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gn = GaussianNB()\n",
    "gn.fit(X_train,np.ravel(y_train))\n",
    "gn.score(X_test,np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5945945945945946"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv = SVC()\n",
    "sv.fit(X_train,np.ravel(y_train))\n",
    "sv.score(X_test,np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
